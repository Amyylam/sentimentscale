{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump's tweets related to China VS Chinese Equities Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### based on past reactions towards Trump's tweet, can I predict whether Chinese equities will react favorably towards his latest tweet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: two classes of sentiment -- \"positive\"/\"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gen80\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@FoxNews  “Trump wins major victories in Chin...</td>\n",
       "      <td>2019-12-17 14:48:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....energy independence manufacturing resilien...</td>\n",
       "      <td>2019-12-16 05:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>....energy independence manufacturing resilien...</td>\n",
       "      <td>2019-12-16 05:05:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chuck Schumer sat for years during the Obama A...</td>\n",
       "      <td>2019-12-14 19:09:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have agreed to a very large Phase One Deal ...</td>\n",
       "      <td>2019-12-13 15:25:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          created_at\n",
       "0  .@FoxNews  “Trump wins major victories in Chin... 2019-12-17 14:48:50\n",
       "1  ....energy independence manufacturing resilien... 2019-12-16 05:28:18\n",
       "2  ....energy independence manufacturing resilien... 2019-12-16 05:05:08\n",
       "3  Chuck Schumer sat for years during the Obama A... 2019-12-14 19:09:26\n",
       "4  We have agreed to a very large Phase One Deal ... 2019-12-13 15:25:47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%m-%d-%Y %H:%M:%S')\n",
    "    \n",
    "\n",
    "trump_df = pd.read_csv(r\"D:\\Documents\\Docs_oldnew\\trump_tweet_api\\Trump_tweets_China_since2016.txt\", parse_dates=['created_at'], date_parser=dateparse)\n",
    "trump_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 365 entries, 0 to 364\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   text        365 non-null    object        \n",
      " 1   created_at  365 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 5.8+ KB\n"
     ]
    }
   ],
   "source": [
    "trump_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonrepeat_text =trump_df[['text']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "            355, 356, 357, 358, 359, 360, 361, 362, 363, 364],\n",
       "           dtype='int64', length=358)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonrepeat_text.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@FoxNews  “Trump wins major victories in Chin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....energy independence manufacturing resilien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>....energy independence manufacturing resilien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chuck Schumer sat for years during the Obama A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have agreed to a very large Phase One Deal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  .@FoxNews  “Trump wins major victories in Chin...\n",
       "1  ....energy independence manufacturing resilien...\n",
       "2  ....energy independence manufacturing resilien...\n",
       "3  Chuck Schumer sat for years during the Obama A...\n",
       "4  We have agreed to a very large Phase One Deal ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonrepeat_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonrepeat_datetime = trump_df['created_at'][nonrepeat_text.index]\n",
    "\n",
    "#account for timezone difference btw NY and HK\n",
    "time_zoneadjusted =nonrepeat_datetime + pd.DateOffset(hours= +13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#object type of datetime column\n",
    "type(nonrepeat_datetime[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>record_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@FoxNews  “Trump wins major victories in Chin...</td>\n",
       "      <td>2019-12-18 03:48:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....energy independence manufacturing resilien...</td>\n",
       "      <td>2019-12-16 18:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>....energy independence manufacturing resilien...</td>\n",
       "      <td>2019-12-16 18:05:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chuck Schumer sat for years during the Obama A...</td>\n",
       "      <td>2019-12-15 08:09:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have agreed to a very large Phase One Deal ...</td>\n",
       "      <td>2019-12-14 04:25:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         record_time\n",
       "0  .@FoxNews  “Trump wins major victories in Chin... 2019-12-18 03:48:50\n",
       "1  ....energy independence manufacturing resilien... 2019-12-16 18:28:18\n",
       "2  ....energy independence manufacturing resilien... 2019-12-16 18:05:08\n",
       "3  Chuck Schumer sat for years during the Obama A... 2019-12-15 08:09:26\n",
       "4  We have agreed to a very large Phase One Deal ... 2019-12-14 04:25:47"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonrepeat_text['record_time'] = time_zoneadjusted\n",
    "nonrepeat_text.head()\n",
    "#neccessary to make it into index?? so as to do nested index filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try extracting the hour\n",
    "#nonrepeat_text['record_time'].dt.hour\n",
    "\n",
    "#? use df.between_time('00:00', '6:00') ## this is filtering on a certain criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to-do:\n",
    "# split into a column in date, another in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-09 09:15:20</th>\n",
       "      <td>Crooked Hillary just can't close the deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-14 14:03:02</th>\n",
       "      <td>If Crooked Hillary Clinton can't close the dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-18 00:37:03</th>\n",
       "      <td>The pathetic new hit ad against me misrepresen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-18 00:46:22</th>\n",
       "      <td>Crooked Hillary Clinton put out an ad where I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-20 22:47:09</th>\n",
       "      <td>Crooked Hillary has zero imagination and even ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text\n",
       "record_time                                                           \n",
       "2016-05-09 09:15:20  Crooked Hillary just can't close the deal with...\n",
       "2016-05-14 14:03:02  If Crooked Hillary Clinton can't close the dea...\n",
       "2016-05-18 00:37:03  The pathetic new hit ad against me misrepresen...\n",
       "2016-05-18 00:46:22  Crooked Hillary Clinton put out an ad where I ...\n",
       "2016-05-20 22:47:09  Crooked Hillary has zero imagination and even ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the datetime index in natural order\n",
    "\n",
    "adjusted_df = nonrepeat_text.set_index('record_time').sort_index()\n",
    "adjusted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_df =adjusted_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(9, 15, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the date component from datetime object\n",
    "adjusted_df['record_time'][0].date()\n",
    "#get the time component \n",
    "adjusted_df['record_time'][0].time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusted_df['year_ind'] =adjusted_df.index.year\n",
    "#adjusted_df['mon_ind'] =adjusted_df.index.month\n",
    "#adjusted_df['day_ind'] =adjusted_df.index.day\n",
    "#adjusted_df['day_ind'].head()\n",
    "#adjusted_df.to_datetime([adjusted_df['year_ind'], adjusted_df['mon_ind'], adjusted_df['day_ind']])\n",
    "\n",
    "#pd.to_datetime(adjusted_df.index, format='%Y%m%d', errors='ignore')\n",
    "\n",
    "#t.apply(lambda x: x.date()) \n",
    "\n",
    "adjusted_df['date']=adjusted_df['record_time'].apply(lambda x: x.date())\n",
    "adjusted_df['time']=adjusted_df['record_time'].apply(lambda x: x.time())\n",
    "adjusted_df['day_of_week'] = adjusted_df['record_time'].apply(lambda x:x.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_time</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-09 09:15:20</td>\n",
       "      <td>Crooked Hillary just can't close the deal with...</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>09:15:20</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-14 14:03:02</td>\n",
       "      <td>If Crooked Hillary Clinton can't close the dea...</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>14:03:02</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-05-18 00:37:03</td>\n",
       "      <td>The pathetic new hit ad against me misrepresen...</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>00:37:03</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-05-18 00:46:22</td>\n",
       "      <td>Crooked Hillary Clinton put out an ad where I ...</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>00:46:22</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-20 22:47:09</td>\n",
       "      <td>Crooked Hillary has zero imagination and even ...</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>22:47:09</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          record_time                                               text  \\\n",
       "0 2016-05-09 09:15:20  Crooked Hillary just can't close the deal with...   \n",
       "1 2016-05-14 14:03:02  If Crooked Hillary Clinton can't close the dea...   \n",
       "2 2016-05-18 00:37:03  The pathetic new hit ad against me misrepresen...   \n",
       "3 2016-05-18 00:46:22  Crooked Hillary Clinton put out an ad where I ...   \n",
       "4 2016-05-20 22:47:09  Crooked Hillary has zero imagination and even ...   \n",
       "\n",
       "         date      time day_of_week  \n",
       "0  2016-05-09  09:15:20      Monday  \n",
       "1  2016-05-14  14:03:02    Saturday  \n",
       "2  2016-05-18  00:37:03   Wednesday  \n",
       "3  2016-05-18  00:46:22   Wednesday  \n",
       "4  2016-05-20  22:47:09      Friday  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_df = adjusted_df.drop(columns = ['record_time']).set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-09</th>\n",
       "      <td>Monday</td>\n",
       "      <td>09:15:20</td>\n",
       "      <td>Crooked Hillary just can't close the deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-14</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>14:03:02</td>\n",
       "      <td>If Crooked Hillary Clinton can't close the dea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-18</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>00:37:03</td>\n",
       "      <td>The pathetic new hit ad against me misrepresen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-18</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>00:46:22</td>\n",
       "      <td>Crooked Hillary Clinton put out an ad where I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-20</th>\n",
       "      <td>Friday</td>\n",
       "      <td>22:47:09</td>\n",
       "      <td>Crooked Hillary has zero imagination and even ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_of_week      time  \\\n",
       "date                               \n",
       "2016-05-09      Monday  09:15:20   \n",
       "2016-05-14    Saturday  14:03:02   \n",
       "2016-05-18   Wednesday  00:37:03   \n",
       "2016-05-18   Wednesday  00:46:22   \n",
       "2016-05-20      Friday  22:47:09   \n",
       "\n",
       "                                                         text  \n",
       "date                                                           \n",
       "2016-05-09  Crooked Hillary just can't close the deal with...  \n",
       "2016-05-14  If Crooked Hillary Clinton can't close the dea...  \n",
       "2016-05-18  The pathetic new hit ad against me misrepresen...  \n",
       "2016-05-18  Crooked Hillary Clinton put out an ad where I ...  \n",
       "2016-05-20  Crooked Hillary has zero imagination and even ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_df = adjusted_df[['day_of_week','time','text']]\n",
    "adjusted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-09</th>\n",
       "      <td>20279.90039</td>\n",
       "      <td>20303.18945</td>\n",
       "      <td>20125.77930</td>\n",
       "      <td>20156.81055</td>\n",
       "      <td>1323285400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-10</th>\n",
       "      <td>19962.42969</td>\n",
       "      <td>20294.46094</td>\n",
       "      <td>19962.42969</td>\n",
       "      <td>20242.67969</td>\n",
       "      <td>1446925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-11</th>\n",
       "      <td>20347.75977</td>\n",
       "      <td>20347.75977</td>\n",
       "      <td>20008.91992</td>\n",
       "      <td>20055.28906</td>\n",
       "      <td>1337926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-12</th>\n",
       "      <td>20100.50000</td>\n",
       "      <td>20100.50000</td>\n",
       "      <td>19863.61914</td>\n",
       "      <td>19915.46094</td>\n",
       "      <td>1150409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-13</th>\n",
       "      <td>19843.49023</td>\n",
       "      <td>19881.91016</td>\n",
       "      <td>19594.60938</td>\n",
       "      <td>19719.28906</td>\n",
       "      <td>1758498600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open        high           low        close      volume\n",
       "date                                                                      \n",
       "2016-05-09  20279.90039  20303.18945  20125.77930  20156.81055  1323285400\n",
       "2016-05-10  19962.42969  20294.46094  19962.42969  20242.67969  1446925800\n",
       "2016-05-11  20347.75977  20347.75977  20008.91992  20055.28906  1337926500\n",
       "2016-05-12  20100.50000  20100.50000  19863.61914  19915.46094  1150409200\n",
       "2016-05-13  19843.49023  19881.91016  19594.60938  19719.28906  1758498600"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HSCE_df =pd.read_csv(r'D:\\Documents\\Docs_oldnew\\trump_tweet_api\\HSCE_since2016May.csv', index_col = 0, parse_dates = True)\n",
    "HSCE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>abs_change</th>\n",
       "      <th>pct_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-09</th>\n",
       "      <td>20279.90039</td>\n",
       "      <td>20303.18945</td>\n",
       "      <td>20125.77930</td>\n",
       "      <td>20156.81055</td>\n",
       "      <td>1323285400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-10</th>\n",
       "      <td>19962.42969</td>\n",
       "      <td>20294.46094</td>\n",
       "      <td>19962.42969</td>\n",
       "      <td>20242.67969</td>\n",
       "      <td>1446925800</td>\n",
       "      <td>85.86914</td>\n",
       "      <td>0.426006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-11</th>\n",
       "      <td>20347.75977</td>\n",
       "      <td>20347.75977</td>\n",
       "      <td>20008.91992</td>\n",
       "      <td>20055.28906</td>\n",
       "      <td>1337926500</td>\n",
       "      <td>-187.39063</td>\n",
       "      <td>-0.925720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-12</th>\n",
       "      <td>20100.50000</td>\n",
       "      <td>20100.50000</td>\n",
       "      <td>19863.61914</td>\n",
       "      <td>19915.46094</td>\n",
       "      <td>1150409200</td>\n",
       "      <td>-139.82812</td>\n",
       "      <td>-0.697213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-13</th>\n",
       "      <td>19843.49023</td>\n",
       "      <td>19881.91016</td>\n",
       "      <td>19594.60938</td>\n",
       "      <td>19719.28906</td>\n",
       "      <td>1758498600</td>\n",
       "      <td>-196.17188</td>\n",
       "      <td>-0.985023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open        high           low        close      volume  \\\n",
       "date                                                                         \n",
       "2016-05-09  20279.90039  20303.18945  20125.77930  20156.81055  1323285400   \n",
       "2016-05-10  19962.42969  20294.46094  19962.42969  20242.67969  1446925800   \n",
       "2016-05-11  20347.75977  20347.75977  20008.91992  20055.28906  1337926500   \n",
       "2016-05-12  20100.50000  20100.50000  19863.61914  19915.46094  1150409200   \n",
       "2016-05-13  19843.49023  19881.91016  19594.60938  19719.28906  1758498600   \n",
       "\n",
       "            abs_change  pct_change  \n",
       "date                                \n",
       "2016-05-09         NaN         NaN  \n",
       "2016-05-10    85.86914    0.426006  \n",
       "2016-05-11  -187.39063   -0.925720  \n",
       "2016-05-12  -139.82812   -0.697213  \n",
       "2016-05-13  -196.17188   -0.985023  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get absolute change and percentage change over previous closing price\n",
    "\n",
    "HSCE_df['abs_change'] = HSCE_df['close'] - HSCE_df['close'].shift(periods =1)\n",
    "HSCE_df['pct_change'] = (HSCE_df['abs_change'] / HSCE_df['close'].shift(periods=1))*100 \n",
    "\n",
    "HSCE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSCE_df['sign_change'] = HSCE_df['pct_change'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>abs_change</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>sign_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-09</th>\n",
       "      <td>20279.90039</td>\n",
       "      <td>20303.18945</td>\n",
       "      <td>20125.77930</td>\n",
       "      <td>20156.81055</td>\n",
       "      <td>1323285400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-10</th>\n",
       "      <td>19962.42969</td>\n",
       "      <td>20294.46094</td>\n",
       "      <td>19962.42969</td>\n",
       "      <td>20242.67969</td>\n",
       "      <td>1446925800</td>\n",
       "      <td>85.86914</td>\n",
       "      <td>0.426006</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-11</th>\n",
       "      <td>20347.75977</td>\n",
       "      <td>20347.75977</td>\n",
       "      <td>20008.91992</td>\n",
       "      <td>20055.28906</td>\n",
       "      <td>1337926500</td>\n",
       "      <td>-187.39063</td>\n",
       "      <td>-0.925720</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-12</th>\n",
       "      <td>20100.50000</td>\n",
       "      <td>20100.50000</td>\n",
       "      <td>19863.61914</td>\n",
       "      <td>19915.46094</td>\n",
       "      <td>1150409200</td>\n",
       "      <td>-139.82812</td>\n",
       "      <td>-0.697213</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-13</th>\n",
       "      <td>19843.49023</td>\n",
       "      <td>19881.91016</td>\n",
       "      <td>19594.60938</td>\n",
       "      <td>19719.28906</td>\n",
       "      <td>1758498600</td>\n",
       "      <td>-196.17188</td>\n",
       "      <td>-0.985023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   open        high           low        close      volume  \\\n",
       "date                                                                         \n",
       "2016-05-09  20279.90039  20303.18945  20125.77930  20156.81055  1323285400   \n",
       "2016-05-10  19962.42969  20294.46094  19962.42969  20242.67969  1446925800   \n",
       "2016-05-11  20347.75977  20347.75977  20008.91992  20055.28906  1337926500   \n",
       "2016-05-12  20100.50000  20100.50000  19863.61914  19915.46094  1150409200   \n",
       "2016-05-13  19843.49023  19881.91016  19594.60938  19719.28906  1758498600   \n",
       "\n",
       "            abs_change  pct_change  sign_change  \n",
       "date                                             \n",
       "2016-05-09         NaN         NaN        False  \n",
       "2016-05-10    85.86914    0.426006         True  \n",
       "2016-05-11  -187.39063   -0.925720        False  \n",
       "2016-05-12  -139.82812   -0.697213        False  \n",
       "2016-05-13  -196.17188   -0.985023        False  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HSCE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSCE_extract =HSCE_df[['close','pct_change','sign_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(HSCE_extract.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>close</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>sign_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-05-09</th>\n",
       "      <td>Monday</td>\n",
       "      <td>09:15:20</td>\n",
       "      <td>Crooked Hillary just can't close the deal with...</td>\n",
       "      <td>20156.81055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20242.67969</td>\n",
       "      <td>0.426006</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20055.28906</td>\n",
       "      <td>-0.925720</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19915.46094</td>\n",
       "      <td>-0.697213</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19719.28906</td>\n",
       "      <td>-0.985023</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_of_week      time  \\\n",
       "date                               \n",
       "2016-05-09      Monday  09:15:20   \n",
       "2016-05-10         NaN       NaN   \n",
       "2016-05-11         NaN       NaN   \n",
       "2016-05-12         NaN       NaN   \n",
       "2016-05-13         NaN       NaN   \n",
       "\n",
       "                                                         text        close  \\\n",
       "date                                                                         \n",
       "2016-05-09  Crooked Hillary just can't close the deal with...  20156.81055   \n",
       "2016-05-10                                                NaN  20242.67969   \n",
       "2016-05-11                                                NaN  20055.28906   \n",
       "2016-05-12                                                NaN  19915.46094   \n",
       "2016-05-13                                                NaN  19719.28906   \n",
       "\n",
       "            pct_change sign_change  \n",
       "date                                \n",
       "2016-05-09         NaN       False  \n",
       "2016-05-10    0.426006        True  \n",
       "2016-05-11   -0.925720       False  \n",
       "2016-05-12   -0.697213       False  \n",
       "2016-05-13   -0.985023       False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next_day performance is missing if drop_na().. no good to miss those reactions\n",
    "##to-do: need to check the weekday as well; and holidays\n",
    "\n",
    "## if his tweet is on Sat and Sun, fill_na with next-day performance\n",
    "\n",
    "tweet_HSCE_react = pd.merge(adjusted_df,HSCE_extract, how = 'outer', left_index=True, right_index=True)\n",
    "tweet_HSCE_react.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>close</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>sign_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22885.91016</td>\n",
       "      <td>-0.711718</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22898.51953</td>\n",
       "      <td>0.055097</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22949.85938</td>\n",
       "      <td>0.224206</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23049.11914</td>\n",
       "      <td>0.432507</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23374.16992</td>\n",
       "      <td>1.410253</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_of_week time text        close  pct_change sign_change\n",
       "date                                                                 \n",
       "2017-01-20         NaN  NaN  NaN  22885.91016   -0.711718       False\n",
       "2017-01-23         NaN  NaN  NaN  22898.51953    0.055097        True\n",
       "2017-01-24         NaN  NaN  NaN  22949.85938    0.224206        True\n",
       "2017-01-25         NaN  NaN  NaN  23049.11914    0.432507        True\n",
       "2017-01-26         NaN  NaN  NaN  23374.16992    1.410253        True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check only tweets after Trump inaugurated\n",
    "\n",
    "tweets_inau_df =tweet_HSCE_react['2017-01-20':]\n",
    "tweets_inau_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>close</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>sign_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-09</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>03:50:59</td>\n",
       "      <td>It was a great honor to have President Xi Jinp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>07:55:23</td>\n",
       "      <td>Leaving Hamburg for Washington D.C. and the WH...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>12:29:05</td>\n",
       "      <td>I am very disappointed in China. Our foolish p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>12:35:13</td>\n",
       "      <td>...they do NOTHING for us with North Korea jus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>11:44:34</td>\n",
       "      <td>The United Nations Security Council just voted...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_of_week      time  \\\n",
       "date                               \n",
       "2017-04-09      Sunday  03:50:59   \n",
       "2017-07-09      Sunday  07:55:23   \n",
       "2017-07-30      Sunday  12:29:05   \n",
       "2017-07-30      Sunday  12:35:13   \n",
       "2017-08-06      Sunday  11:44:34   \n",
       "\n",
       "                                                         text  close  \\\n",
       "date                                                                   \n",
       "2017-04-09  It was a great honor to have President Xi Jinp...    NaN   \n",
       "2017-07-09  Leaving Hamburg for Washington D.C. and the WH...    NaN   \n",
       "2017-07-30  I am very disappointed in China. Our foolish p...    NaN   \n",
       "2017-07-30  ...they do NOTHING for us with North Korea jus...    NaN   \n",
       "2017-08-06  The United Nations Security Council just voted...    NaN   \n",
       "\n",
       "            pct_change sign_change  \n",
       "date                                \n",
       "2017-04-09         NaN         NaN  \n",
       "2017-07-09         NaN         NaN  \n",
       "2017-07-30         NaN         NaN  \n",
       "2017-07-30         NaN         NaN  \n",
       "2017-08-06         NaN         NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_inau_df[tweets_inau_df['day_of_week'] == 'Sunday'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_inau_df[tweets_inau_df['day_of_week'] == 'Sunday'][['close']].fillna(value= close_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-02-13', '2017-03-20', '2017-04-24', '2017-05-01',\n",
       "               '2017-05-15', '2017-11-06', '2018-04-09', '2018-04-30',\n",
       "               '2018-05-07', '2018-07-23', '2018-08-27', '2018-08-27',\n",
       "               '2018-11-12', '2018-12-10', '2018-12-17', '2018-12-17',\n",
       "               '2018-12-24', '2019-03-04', '2019-05-06', '2019-05-13',\n",
       "               '2019-05-13', '2019-05-13', '2019-05-13', '2019-05-13',\n",
       "               '2019-05-13', '2019-05-13', '2019-05-13', '2019-05-13',\n",
       "               '2019-05-13', '2019-05-13', '2019-06-10', '2019-07-01',\n",
       "               '2019-07-15', '2019-07-29', '2019-07-29', '2019-07-29',\n",
       "               '2019-08-26', '2019-08-26', '2019-08-26', '2019-08-26',\n",
       "               '2019-08-26', '2019-08-26', '2019-08-26', '2019-08-26',\n",
       "               '2019-08-26', '2019-08-26', '2019-09-02', '2019-09-09',\n",
       "               '2019-09-09', '2019-10-07', '2019-10-14', '2019-10-14',\n",
       "               '2019-10-14', '2019-10-14', '2019-12-09', '2019-12-16',\n",
       "               '2019-12-16'],\n",
       "              dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##this need  a shift of business_day\n",
    "\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "#backup: tweets_inau_df[tweets_inau_df['day_of_week'] == 'Saturday'].index.\n",
    "Sat_shift_newdate= tweets_inau_df[tweets_inau_df['day_of_week'] == 'Saturday'].index.map(lambda x:x+0*BDay())\n",
    "Sat_shift_newdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSCE_extract.loc['2017-02-13']['close']\n",
    "\n",
    "#close_values = HSCE_extract.loc[Sat_shift_newdate]['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a sentiment classifier with the stock market reaction as a distant supervised label set\n",
    "\n",
    "- negative change over previous day means negative sentiment reaction towards Trump's speech\n",
    "- vice versa\n",
    "- not ideal compared  to best human-annotated labels but a workaround to save time and labour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>close</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>sign_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>Friday</td>\n",
       "      <td>11:16:17</td>\n",
       "      <td>The meeting next week with China will be a ver...</td>\n",
       "      <td>24111.58984</td>\n",
       "      <td>-0.779800</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-12</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>00:59:04</td>\n",
       "      <td>I explained to the President of China that a t...</td>\n",
       "      <td>24313.50000</td>\n",
       "      <td>0.934219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-12</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>01:03:43</td>\n",
       "      <td>North Korea is looking for trouble. If China d...</td>\n",
       "      <td>24313.50000</td>\n",
       "      <td>0.934219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-13</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>01:22:22</td>\n",
       "      <td>Had a very good call last night with the Presi...</td>\n",
       "      <td>24261.66016</td>\n",
       "      <td>-0.213214</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-21</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>07:38:11</td>\n",
       "      <td>While I greatly appreciate the efforts of Pres...</td>\n",
       "      <td>25694.58008</td>\n",
       "      <td>-0.574464</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_of_week      time  \\\n",
       "date                               \n",
       "2017-03-31      Friday  11:16:17   \n",
       "2017-04-12   Wednesday  00:59:04   \n",
       "2017-04-12   Wednesday  01:03:43   \n",
       "2017-04-13    Thursday  01:22:22   \n",
       "2017-06-21   Wednesday  07:38:11   \n",
       "\n",
       "                                                         text        close  \\\n",
       "date                                                                         \n",
       "2017-03-31  The meeting next week with China will be a ver...  24111.58984   \n",
       "2017-04-12  I explained to the President of China that a t...  24313.50000   \n",
       "2017-04-12  North Korea is looking for trouble. If China d...  24313.50000   \n",
       "2017-04-13  Had a very good call last night with the Presi...  24261.66016   \n",
       "2017-06-21  While I greatly appreciate the efforts of Pres...  25694.58008   \n",
       "\n",
       "            pct_change sign_change  \n",
       "date                                \n",
       "2017-03-31   -0.779800       False  \n",
       "2017-04-12    0.934219        True  \n",
       "2017-04-12    0.934219        True  \n",
       "2017-04-13   -0.213214       False  \n",
       "2017-06-21   -0.574464       False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#211 rows × 6 columns\n",
    "\n",
    "tweets_inau_nona = tweets_inau_df.dropna()\n",
    "tweets_inau_nona.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to-do: check if time is before 9:30 or happening during market open hours or after market hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= tweets_inau_nona['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-03-31    The meeting next week with China will be a ver...\n",
       "2017-04-12    I explained to the President of China that a t...\n",
       "2017-04-12    North Korea is looking for trouble. If China d...\n",
       "2017-04-13    Had a very good call last night with the Presi...\n",
       "2017-06-21    While I greatly appreciate the efforts of Pres...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gen80\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# transform 'sign_change' column to numerical values to make it a 'y' (answer column) to train ML model to predict answers(y) given features(X)\n",
    "\n",
    "le = LabelEncoder() \n",
    "tweets_inau_nona.loc[:,'sign_change'] = le.fit_transform(tweets_inau_nona['sign_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-03-31    0\n",
       "2017-04-12    1\n",
       "2017-04-12    1\n",
       "2017-04-13    0\n",
       "2017-06-21    0\n",
       "Name: sign_change, dtype: int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_inau_nona['sign_change'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweets_inau_nona['sign_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-03-31    0\n",
       "2017-04-12    1\n",
       "2017-04-12    1\n",
       "2017-04-13    0\n",
       "2017-06-21    0\n",
       "Name: sign_change, dtype: int32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a features set X by turning the text strings into Term-frequency-adjusted bag-of-words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer()\n",
    "\n",
    "X_train_tsf = tfidf.fit_transform(X_train).tocsc()\n",
    "X_test_tsf = tfidf.transform(X_test).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all the vocab from the text strings and their total occurences in input data \n",
    "\n",
    "#tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5204608 , 5.43675153, 5.03128643, ..., 4.74360435, 5.43675153,\n",
       "       4.74360435])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check inverse document frequency\n",
    "tfidf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the vocabs\n",
    "#tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 1418)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tsf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 1418)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tsf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Binary Naive Bayes Machine Learning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb =BernoulliNB()\n",
    "bnb.fit(X_train_tsf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9940476190476191"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_train_tsf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046511627906976"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation-- high training accuracy does not translate well in test score\n",
    "bnb.score(X_test_tsf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.32022832, -4.41884061, -3.72569343, ..., -3.72569343,\n",
       "        -4.41884061, -3.72569343]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for each word in the binary Naive Bayes model\n",
    "bnb.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test a string for prediction. model predicted it to have positive sentiment\n",
    "bnb.predict(X_test_tsf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China is doing very badly worst year in 27 - was supposed to start buying our agricultural product now - no signs that they are doing so. That is the problem with China they just don’t come through. Our Economy has become MUCH larger than the Chinese Economy is last 3 years....'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare the prediction with human judgement: this sentence is actually Neutral on market\n",
    "##to-do: need to add a 'Neutral' class to original labeling of y\n",
    "\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another type of binary classifier to see if the model can get better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_tsf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46511627906976744"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new model result also not doing very good on the test data. \n",
    "\n",
    "lr.score(X_test_tsf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09350873, -0.06586615, -0.01435824, ..., -0.05584902,\n",
       "        -0.10322061, -0.073659  ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49292213, 0.50707787]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how confident the prediction is for each of positive/negative class labels\n",
    "# below the prediction is not very certain which is correct label\n",
    "\n",
    "lr.predict_proba(X_test_tsf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what weights the binary classifier has learned for each word\n",
    "\n",
    "vocab = tfidf.get_feature_names()\n",
    "weights = lr.coef_.flatten()\n",
    "\n",
    "# get  20 most weighted negative/positive words\n",
    "inds = np.argsort(lr.coef_.flatten())\n",
    "negative_words = [vocab[index] for index in inds[:20]]\n",
    "positive_words = [vocab[index] for index in inds[-20:]]\n",
    "neg_words_weights = [(weights[index]) for index in inds[:20]]\n",
    "pos_words_weights = [(weights[index]) for index in inds[-20:]]\n",
    "\n",
    "df = pd.DataFrame({'Neg feats':negative_words, 'Neg weights':neg_words_weights, \n",
    "                   'Pos feats':positive_words, 'Pos weights':pos_words_weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg feats</th>\n",
       "      <th>Neg weights</th>\n",
       "      <th>Pos feats</th>\n",
       "      <th>Pos weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so</td>\n",
       "      <td>-0.587945</td>\n",
       "      <td>well</td>\n",
       "      <td>0.325938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>had</td>\n",
       "      <td>-0.541165</td>\n",
       "      <td>others</td>\n",
       "      <td>0.332928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chinese</td>\n",
       "      <td>-0.464427</td>\n",
       "      <td>them</td>\n",
       "      <td>0.334355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>-0.460902</td>\n",
       "      <td>out</td>\n",
       "      <td>0.344501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>korea</td>\n",
       "      <td>-0.443129</td>\n",
       "      <td>it</td>\n",
       "      <td>0.347864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>playing</td>\n",
       "      <td>-0.411239</td>\n",
       "      <td>massive</td>\n",
       "      <td>0.350765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>can</td>\n",
       "      <td>-0.381958</td>\n",
       "      <td>is</td>\n",
       "      <td>0.352805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>due</td>\n",
       "      <td>-0.375781</td>\n",
       "      <td>for</td>\n",
       "      <td>0.378051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>not</td>\n",
       "      <td>-0.356889</td>\n",
       "      <td>lavar</td>\n",
       "      <td>0.388650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>take</td>\n",
       "      <td>-0.355290</td>\n",
       "      <td>money</td>\n",
       "      <td>0.389250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>usa</td>\n",
       "      <td>-0.336790</td>\n",
       "      <td>after</td>\n",
       "      <td>0.402903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anything</td>\n",
       "      <td>-0.332713</td>\n",
       "      <td>move</td>\n",
       "      <td>0.409202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>does</td>\n",
       "      <td>-0.331754</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>0.414073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>put</td>\n",
       "      <td>-0.318932</td>\n",
       "      <td>make</td>\n",
       "      <td>0.416158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at</td>\n",
       "      <td>-0.318027</td>\n",
       "      <td>solve</td>\n",
       "      <td>0.437238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ve</td>\n",
       "      <td>-0.311611</td>\n",
       "      <td>very</td>\n",
       "      <td>0.484641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>which</td>\n",
       "      <td>-0.311460</td>\n",
       "      <td>big</td>\n",
       "      <td>0.509373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>he</td>\n",
       "      <td>-0.301530</td>\n",
       "      <td>farmers</td>\n",
       "      <td>0.536330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>joe</td>\n",
       "      <td>-0.299517</td>\n",
       "      <td>problem</td>\n",
       "      <td>0.541933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rate</td>\n",
       "      <td>-0.297006</td>\n",
       "      <td>will</td>\n",
       "      <td>0.622833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neg feats  Neg weights     Pos feats  Pos weights\n",
       "0         so    -0.587945          well     0.325938\n",
       "1        had    -0.541165        others     0.332928\n",
       "2    chinese    -0.464427          them     0.334355\n",
       "3         no    -0.460902           out     0.344501\n",
       "4      korea    -0.443129            it     0.347864\n",
       "5    playing    -0.411239       massive     0.350765\n",
       "6        can    -0.381958            is     0.352805\n",
       "7        due    -0.375781           for     0.378051\n",
       "8        not    -0.356889         lavar     0.388650\n",
       "9       take    -0.355290         money     0.389250\n",
       "10       usa    -0.336790         after     0.402903\n",
       "11  anything    -0.332713          move     0.409202\n",
       "12      does    -0.331754  agricultural     0.414073\n",
       "13       put    -0.318932          make     0.416158\n",
       "14        at    -0.318027         solve     0.437238\n",
       "15        ve    -0.311611          very     0.484641\n",
       "16     which    -0.311460           big     0.509373\n",
       "17        he    -0.301530       farmers     0.536330\n",
       "18       joe    -0.299517       problem     0.541933\n",
       "19      rate    -0.297006          will     0.622833"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##comment-- these is not right. words \"had\" and \"so\" does not have negative meaning in themselves. \"will\" and \"too\" are not positive words.\n",
    "\n",
    "#follow-up: need to remove some stopwords; also have to teach it about vocabulary of pos/neg sentiment\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try removing stopwords when building feature matrix and check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(max_features=5000,                       \n",
    "                      stop_words='english')\n",
    "X_train_counts = vec.fit_transform(X_train) \n",
    "X_test_counts = vec.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_counts,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5581395348837209"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after removing stop-words, accuracy is better than above? 55.8% above\n",
    "\n",
    "##ummm... test score is 65% for 2nd run, versus 53% for 1st run... means the random split did something as sample size too small, not that the model is good\n",
    "lr2.score(X_test_counts,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03045494, -0.07086442, -0.06505135, ..., -0.11892395,\n",
       "        -0.15129027, -0.0556343 ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2056884, 0.7943116]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this prediction from model is confident\n",
    "lr2.predict_proba(X_test_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg feats</th>\n",
       "      <th>Neg weights</th>\n",
       "      <th>Pos feats</th>\n",
       "      <th>Pos weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chinese</td>\n",
       "      <td>-0.617227</td>\n",
       "      <td>summit</td>\n",
       "      <td>0.417075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>does</td>\n",
       "      <td>-0.575310</td>\n",
       "      <td>day</td>\n",
       "      <td>0.422890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usa</td>\n",
       "      <td>-0.552210</td>\n",
       "      <td>fast</td>\n",
       "      <td>0.424448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>playing</td>\n",
       "      <td>-0.525858</td>\n",
       "      <td>currently</td>\n",
       "      <td>0.434890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>let</td>\n",
       "      <td>-0.498426</td>\n",
       "      <td>pouring</td>\n",
       "      <td>0.440874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>believe</td>\n",
       "      <td>-0.487639</td>\n",
       "      <td>talking</td>\n",
       "      <td>0.441090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>advantage</td>\n",
       "      <td>-0.453604</td>\n",
       "      <td>big</td>\n",
       "      <td>0.449126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>korea</td>\n",
       "      <td>-0.452333</td>\n",
       "      <td>probably</td>\n",
       "      <td>0.449845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>million</td>\n",
       "      <td>-0.424802</td>\n",
       "      <td>lavar</td>\n",
       "      <td>0.473788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>future</td>\n",
       "      <td>-0.419119</td>\n",
       "      <td>happens</td>\n",
       "      <td>0.504671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ve</td>\n",
       "      <td>-0.412038</td>\n",
       "      <td>doing</td>\n",
       "      <td>0.506044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>currency</td>\n",
       "      <td>-0.401869</td>\n",
       "      <td>things</td>\n",
       "      <td>0.516940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>greatly</td>\n",
       "      <td>-0.400465</td>\n",
       "      <td>productive</td>\n",
       "      <td>0.527651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>real</td>\n",
       "      <td>-0.391927</td>\n",
       "      <td>money</td>\n",
       "      <td>0.605239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>negotiate</td>\n",
       "      <td>-0.383035</td>\n",
       "      <td>massive</td>\n",
       "      <td>0.615958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ahead</td>\n",
       "      <td>-0.378566</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>0.626718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>better</td>\n",
       "      <td>-0.377657</td>\n",
       "      <td>make</td>\n",
       "      <td>0.653817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rate</td>\n",
       "      <td>-0.374216</td>\n",
       "      <td>farmers</td>\n",
       "      <td>0.655412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hundreds</td>\n",
       "      <td>-0.370375</td>\n",
       "      <td>solve</td>\n",
       "      <td>0.712668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>treated</td>\n",
       "      <td>-0.369818</td>\n",
       "      <td>problem</td>\n",
       "      <td>0.768954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Neg feats  Neg weights     Pos feats  Pos weights\n",
       "0     chinese    -0.617227        summit     0.417075\n",
       "1        does    -0.575310           day     0.422890\n",
       "2         usa    -0.552210          fast     0.424448\n",
       "3     playing    -0.525858     currently     0.434890\n",
       "4         let    -0.498426       pouring     0.440874\n",
       "5     believe    -0.487639       talking     0.441090\n",
       "6   advantage    -0.453604           big     0.449126\n",
       "7       korea    -0.452333      probably     0.449845\n",
       "8     million    -0.424802         lavar     0.473788\n",
       "9      future    -0.419119       happens     0.504671\n",
       "10         ve    -0.412038         doing     0.506044\n",
       "11   currency    -0.401869        things     0.516940\n",
       "12    greatly    -0.400465    productive     0.527651\n",
       "13       real    -0.391927         money     0.605239\n",
       "14  negotiate    -0.383035       massive     0.615958\n",
       "15      ahead    -0.378566  agricultural     0.626718\n",
       "16     better    -0.377657          make     0.653817\n",
       "17       rate    -0.374216       farmers     0.655412\n",
       "18   hundreds    -0.370375         solve     0.712668\n",
       "19    treated    -0.369818       problem     0.768954"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see if it learnt better weightings for each word\n",
    "# top 20 weighted positive/nagative-sentiment associated words: much more correct in identifying positive words than above\n",
    "\n",
    "vocab = vec.get_feature_names()\n",
    "weights = lr2.coef_.flatten()\n",
    "\n",
    "inds = np.argsort(lr2.coef_.flatten())\n",
    "negative_words = [vocab[index] for index in inds[:20]]\n",
    "positive_words = [vocab[index] for index in inds[-20:]]\n",
    "neg_words_weights = [(weights[index]) for index in inds[:20]]\n",
    "pos_words_weights = [(weights[index]) for index in inds[-20:]]\n",
    "\n",
    "df2 = pd.DataFrame({'Neg feats':negative_words, 'Neg weights':neg_words_weights, \n",
    "                   'Pos feats':positive_words, 'Pos weights':pos_words_weights})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to pass a custom vocab dict to tfidf_vectorizer and see if it can achieve better training results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "manual_vocabulary = {}\n",
    "\n",
    "file = open(r'D:\\Documents\\Docs_oldnew\\trump_tweet_api\\keywords_count_dict.txt')\n",
    "count = 0\n",
    "for line in file:\n",
    "    \n",
    "    manual_vocabulary[line.split(':')[0]] = count\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try adding some manually-defined keywords with weights(custom vocabulary)\n",
    "#manual_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(vocabulary = manual_vocabulary)\n",
    "\n",
    "X_train_tsf2 = tfidf2.fit_transform(X_train).tocsc()\n",
    "X_test_tsf2 = tfidf2.transform(X_test).tocsc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.32323623, 2.60353819, 3.73200344, 5.43675153, 4.18398857,\n",
       "       6.12989871, 5.03128643, 5.43675153, 3.73200344, 6.12989871,\n",
       "       3.82731362, 3.56494936, 4.18398857, 4.5204608 , 6.12989871,\n",
       "       6.12989871, 5.03128643, 6.12989871, 5.43675153, 5.43675153,\n",
       "       4.74360435, 5.03128643, 4.5204608 , 2.87180218, 3.93267414,\n",
       "       5.43675153, 3.93267414, 4.5204608 , 5.43675153, 6.12989871,\n",
       "       5.03128643, 2.5189808 , 4.5204608 , 4.05045717, 4.05045717,\n",
       "       5.43675153, 4.18398857, 5.43675153, 4.33813925, 6.12989871,\n",
       "       4.5204608 ])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  this custom dictionary has similar inverse document frequencies\n",
    "tfidf2.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf2.get_feature_names()  ##a list of keys of input manual_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['trade', 'deal', 'currency', 'sell', 'products', 'decide', 'agree', 'meet', 'meeting', 'surplus', 'billion', 'money', 'economy', 'economic', 'talk', 'spoken', 'call', 'discuss', 'appreciate', 'grew', 'growth', 'financial', 'hopefully', 'much', 'forward', 'stronger', 'relationship', 'progress', 'disappointed', 'foolish', 'deficit', 'not', 'yet', 'nothing', 'little', 'tax', 'tariff', 'incompetence', 'advantage', 'loss', 'losing'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf2.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now try train a lr model with tfidf2 fed with custom vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6369047619047619\n",
      "0.5116279069767442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### comment: even worse results, probably because the vocab could not cover all words in tweets\n",
    "\n",
    "lr_md = LogisticRegression()\n",
    "lr_md.fit(X_train_tsf2,y_train)\n",
    "print(lr_md.score(X_train_tsf2,y_train))\n",
    "print(lr_md.score(X_test_tsf2,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabs</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trade</td>\n",
       "      <td>0.209263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deal</td>\n",
       "      <td>0.352278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currency</td>\n",
       "      <td>-0.845862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sell</td>\n",
       "      <td>0.303063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>products</td>\n",
       "      <td>0.463128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>decide</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agree</td>\n",
       "      <td>-0.057844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meet</td>\n",
       "      <td>0.330195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meeting</td>\n",
       "      <td>0.031795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>surplus</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>billion</td>\n",
       "      <td>-0.239425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>money</td>\n",
       "      <td>0.790226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>economy</td>\n",
       "      <td>0.135388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>economic</td>\n",
       "      <td>-0.420916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>talk</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spoken</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>call</td>\n",
       "      <td>0.652187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>discuss</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>appreciate</td>\n",
       "      <td>-0.347365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>grew</td>\n",
       "      <td>-0.345630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>growth</td>\n",
       "      <td>0.131248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>financial</td>\n",
       "      <td>-0.040405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hopefully</td>\n",
       "      <td>-0.321160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>much</td>\n",
       "      <td>-0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>forward</td>\n",
       "      <td>-0.160592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stronger</td>\n",
       "      <td>-0.292158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>relationship</td>\n",
       "      <td>0.145067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>progress</td>\n",
       "      <td>1.104290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>0.400221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>foolish</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>deficit</td>\n",
       "      <td>-0.036419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>not</td>\n",
       "      <td>-0.102860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>yet</td>\n",
       "      <td>-0.835075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nothing</td>\n",
       "      <td>-0.331534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>little</td>\n",
       "      <td>-0.581384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tax</td>\n",
       "      <td>-0.336617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tariff</td>\n",
       "      <td>0.334805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>incompetence</td>\n",
       "      <td>-0.172978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>advantage</td>\n",
       "      <td>-0.581232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>losing</td>\n",
       "      <td>0.103253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vocabs   weights\n",
       "0          trade  0.209263\n",
       "1           deal  0.352278\n",
       "2       currency -0.845862\n",
       "3           sell  0.303063\n",
       "4       products  0.463128\n",
       "5         decide  0.000000\n",
       "6          agree -0.057844\n",
       "7           meet  0.330195\n",
       "8        meeting  0.031795\n",
       "9        surplus  0.000000\n",
       "10       billion -0.239425\n",
       "11         money  0.790226\n",
       "12       economy  0.135388\n",
       "13      economic -0.420916\n",
       "14          talk  0.000000\n",
       "15        spoken  0.000000\n",
       "16          call  0.652187\n",
       "17       discuss  0.000000\n",
       "18    appreciate -0.347365\n",
       "19          grew -0.345630\n",
       "20        growth  0.131248\n",
       "21     financial -0.040405\n",
       "22     hopefully -0.321160\n",
       "23          much -0.001290\n",
       "24       forward -0.160592\n",
       "25      stronger -0.292158\n",
       "26  relationship  0.145067\n",
       "27      progress  1.104290\n",
       "28  disappointed  0.400221\n",
       "29       foolish  0.000000\n",
       "30       deficit -0.036419\n",
       "31           not -0.102860\n",
       "32           yet -0.835075\n",
       "33       nothing -0.331534\n",
       "34        little -0.581384\n",
       "35           tax -0.336617\n",
       "36        tariff  0.334805\n",
       "37  incompetence -0.172978\n",
       "38     advantage -0.581232\n",
       "39          loss  0.000000\n",
       "40        losing  0.103253"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ummm these weights are also counter-intuitive for sentiment reactions. \n",
    "\n",
    "manualdict_coefs_df =pd.DataFrame({\"vocabs\":tfidf2.get_feature_names(), \n",
    "              \"weights\":lr_md.coef_[0]})\n",
    "manualdict_coefs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now testing regression models that output continous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_r = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r.fit(X_train_tsf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999999999997"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r.score(X_train_tsf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "##scoring metric is differing from above that it can have negative score\n",
    "\n",
    "##Return the coefficient of determination R^2 of the prediction.\n",
    "## The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22603844988580502"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r.score(X_test_tsf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r2 = LinearRegression()\n",
    "\n",
    "lr_r2.fit(X_train_counts,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13456996620595296"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r2.score(X_test_counts,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.23246604])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regression model predicts a float number, while golden answer is an interger-- hard to score it right\n",
    "\n",
    "lr_r2.predict(X_test_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there's not much valid labeling here.... so learning result is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to-do: need to filter more to have better training\n",
    "#also have to check the correlation of keywords and market response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### also need to narrow the analysis period to after trade war and forever negotiating trade deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wikipedia reference \n",
    "# 2018\n",
    "# January 22: Trump announced tariffs on solar panels and washing machines.[80] About 8% of American solar panel imports in 2017 came from China.[81] Imports of residential washing machines from China totaled about $1.1 billion in 2015.[82]\n",
    "# March 1: Trump announced steel and aluminum tariffs on imports from all countries.[83] The United States had imported about 3% of its steel from China.[84]\n",
    "# March 22: Trump asked the United States trade representative (USTR) to investigate applying tariffs on US$50–60 billion worth of Chinese goods.[85][86][87] He relied on Section 301 of the Trade Act of 1974 for doing so, stating that the proposed tariffs were \"a response to the unfair trade practices of China over the years\", including theft of U.S. intellectual property.[88][85] Over 1,300 categories of Chinese imports were listed for tariffs, including aircraft parts, batteries, flat-panel televisions, medical devices, satellites, and various weapons.[89][90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OH I should use a pretrained sentiment model\n",
    "#coz there're so many words with obvious sentiment that may come up in this new dataset(of Trump)\n",
    "\n",
    "but obviously his unique use of words also needs to be fed into model, as he often uses good words to deliver opposite meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: Train a classifier to predict Sentiment on a wider Ordinal scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out textblob classifier, customly-trained on the 300+ entries hand-annotated dataset related to China"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should expand to use a larger dataset to fully LEARN talk style of Trump on various occasions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path =r'D:\\Documents\\Docs_oldnew\\trump_tweet_api\\sentimentscale\\\\'\n",
    "trump_clf_df =pd.read_csv(annotation_path+'trump_manuallabeling_alldone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>sentiment(0-9)</th>\n",
       "      <th>trade-related(y/n)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China has been taking out massive amounts of m...</td>\n",
       "      <td>1/2/2017 23:47</td>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The failing @nytimes does major FAKE NEWS Chin...</td>\n",
       "      <td>2/10/2017 13:35</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Korea is behaving very badly. They have ...</td>\n",
       "      <td>3/17/2017 13:07</td>\n",
       "      <td>2</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The meeting next week with China will be a ver...</td>\n",
       "      <td>3/30/2017 22:16</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a great honor to have President Xi Jinp...</td>\n",
       "      <td>4/8/2017 14:50</td>\n",
       "      <td>7</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       created_at  \\\n",
       "0  China has been taking out massive amounts of m...   1/2/2017 23:47   \n",
       "1  The failing @nytimes does major FAKE NEWS Chin...  2/10/2017 13:35   \n",
       "2  North Korea is behaving very badly. They have ...  3/17/2017 13:07   \n",
       "3  The meeting next week with China will be a ver...  3/30/2017 22:16   \n",
       "4  It was a great honor to have President Xi Jinp...   4/8/2017 14:50   \n",
       "\n",
       "   sentiment(0-9) trade-related(y/n)  \n",
       "0               1                  y  \n",
       "1               6                  n  \n",
       "2               2                  n  \n",
       "3               2                  y  \n",
       "4               7                  n  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_clf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_clf_labels =trump_clf_df.drop(columns = ['created_at','trade-related(y/n)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment(0-9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China has been taking out massive amounts of m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The failing @nytimes does major FAKE NEWS Chin...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North Korea is behaving very badly. They have ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The meeting next week with China will be a ver...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a great honor to have President Xi Jinp...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment(0-9)\n",
       "0  China has been taking out massive amounts of m...               1\n",
       "1  The failing @nytimes does major FAKE NEWS Chin...               6\n",
       "2  North Korea is behaving very badly. They have ...               2\n",
       "3  The meeting next week with China will be a ver...               2\n",
       "4  It was a great honor to have President Xi Jinp...               7"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment annotations are in a 0-9 scale. 0 being very negative, 9 being very positive\n",
    "\n",
    "trump_clf_labels .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump_clf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a  multiclass classifier\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see golden annotations\n",
    "# for row in trump_clf_labels.iterrows():\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to transform data into a format that Textblob reads\n",
    "import csv\n",
    "\n",
    "train_textlist = []\n",
    "\n",
    "with open(annotation_path+'trump_manuallabeling_2cols.csv', newline='',encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "\n",
    "        train_textlist.append(tuple(row))\n",
    "        \n",
    "#train_textlist[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_textlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set is about two-third of the annotated dataset\n",
    "\n",
    "cl = NaiveBayesClassifier(train_textlist[1:201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('....This money will come from the massive Tariffs being paid to the United States for allowing China and others to do business with us. The Farmers have been â€œforgottenâ€\\x9d for many years. Their time is now!',\n",
       " '4')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_textlist[201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after training, try one prediction with the trained classifier\n",
    "cl.classify(train_textlist[201][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....This money will come from the massive Tariffs being paid to the United States for allowing China and others to do business with us. The Farmers have been â€œforgottenâ€ for many years. Their time is now!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "China will be pumping money into their system and probably reducing interest rates as always in order to make up for the business they are and will be losing. If the Federal Reserve ever did a â€œmatchâ€ it would be game over we win! In any event China wants a deal!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "Looks like Bernie Sanders is history. Sleepy Joe Biden is pulling ahead and think about it Iâ€™m only here because of Sleepy Joe and the man who took him off the 1% trash heap President O! China wants Sleepy Joe BADLY!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  4\n",
      "-------------------------------------------\n",
      "RT @GOPChairwoman: The @realDonaldTrump administration's fight for better trade deals doesn't end with China. The president is working haâ€¦\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Washington Post got it wrong as usual. The U.S. is charging 25% against 250 Billion Dollars of goods shipped from China not 200 BD. Also China is paying a heavy cost in that they will subsidize goods to keep them coming devalue their currency yet companies are moving to.....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "China is subsidizing its product in order that it can continue to be sold in the USA. Many firms are leaving China for other countries including the United States in order to avoid paying the Tariffs. No visible increase in costs or inflation but U.S. is taking Billions!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "....If Mexico produces (which I think they will). Biggest part of deal with Mexico has not yet been revealed! China is similar except they devalue currency and subsidize companies to lessen effect of 25% Tariff. So far little effect to consumer. Companies will relocate to U.S.\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "â€œBiden would be Chinaâ€™s Dream Candidate because there would be no more Tariffs no more demands that China stop stealing our IP things would go back to the old days with Americaâ€™s manufacturers &amp; workers getting shafted. He has Zero Credibility!â€ @IngrahamAngle  So true!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Mario Draghi just announced more stimulus could come which immediately dropped the Euro against the Dollar making it unfairly easier for them to compete against the USA. They have been getting away with this for years along with China and others.\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "Had a very good telephone conversation with President Xi of China. We will be having an extended meeting next week at the G-20 in Japan. Our respective teams will begin talks prior to our meeting.\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "China gets 91% of its Oil from the Straight Japan 62% &amp; many other countries likewise. So why are we protecting the shipping lanes for other countries (many years) for zero compensation. All of these countries should be protecting their own ships on what has always been....\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "After some very important meetings including my meeting with President Xi of China I will be leaving Japan for South Korea (with President Moon). While there if Chairman Kim of North Korea sees this I would meet him at the Border/DMZ just to shake his hand and say Hello(?)!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "I had a great meeting with President Xi of China yesterday far better than expected. I agreed not to increase the already existing Tariffs that we charge China while we continue to negotiate. China has agreed that during the negotiation they will begin purchasing large......\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      ".....again with China as our relationship with them continues to be a very good one. The quality of the transaction is far more important to me than speed. I am in no hurry but things look very good! Their will be no reduction in the Tariffs currently being charged to China.\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "China and Europe playing big currency manipulation game and pumping money into their system in order to compete with USA. We should MATCH or continue being the dummies who sit back and politely watch as other countries continue to play their games - as they have for many years!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "Joe Biden is a reclamation project. Some things are just not salvageable. China and other countries that ripped us off for years are begging for him. He deserted our military our law enforcement and our healthcare. Added more debt than all other Presidents combined. Wonâ€™t win!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "Mexico is doing great at the Border but China is letting us down in that they have not been buying the agricultural products from our great Farmers that they said they would. Hopefully they will start soon!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "Chinaâ€™s 2nd Quarter growth is the slowest it has been in more than 27 years. The United States Tariffs are having a major effect on companies wanting to leave China for non-tariffed countries. Thousands of companies are leaving. This is why China wants to make a deal....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "....with the U.S. and wishes it had not broken the original deal in the first place. In the meantime we are receiving Billions of Dollars in Tariffs from China with possibly much more to come. These Tariffs are paid for by China devaluing &amp; pumping not by the U.S. taxpayer!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Farmers are starting to do great again after 15 years of a downward spiral. The 16 Billion Dollar China â€œreplacementâ€ money didnâ€™t exactly hurt!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "There may or may not be National Security concerns with regard to Google and their relationship with China. If there is a problem we will find out about it. I sincerely hope there is not!!!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Apple will not be given Tariff waiver or relief for Mac Pro parts that are made in China. Make them in the USA no Tariffs!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "The E.U. and China will further lower interest rates and pump money into their systems making it much easier for their manufacturers to sell product. In the meantime and with very low inflation our Fed does nothing - and probably will do very little by comparison. Too bad!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "....countries that know how to play the game against the U.S. Thatâ€™s actually why the E.U. was formed....and for China until now the U.S. has been â€œeasy pickens.â€ The Fed has made all of the wrong moves. A small rate cut is not enough but we will win anyway!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "China is doing very badly worst year in 27 - was supposed to start buying our agricultural product now - no signs that they are doing so. That is the problem with China they just donâ€™t come through. Our Economy has become MUCH larger than the Chinese Economy is last 3 years....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "China has lost 5 million jobs and two million manufacturing jobs due to the Trump Tariffs. Trumps got China back on its heels and the United States is doing great. @AndyPuzder @MariaBartiromo\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "What the Market wanted to hear from Jay Powell and the Federal Reserve was that this was the beginning of a lengthy and aggressive rate-cutting cycle which would keep pace with China The European Union and other countries around the world....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "China Iran &amp; other foreign countries are looking at the Democrat Candidates and â€œdroolingâ€ over the small prospect that they could be dealing with them in the not too distant future. They would be able to rip off our beloved USA like never before. With President Trump NO WAY!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  4\n",
      "-------------------------------------------\n",
      "Our representatives have just returned from China where they had constructive talks having to do with a future Trade Deal. We thought we had a deal with China three months ago but sadly China decided to re-negotiate the deal prior to signing. More recently China agreed to...\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "...during the talks the U.S. will start on September 1st putting a small additional Tariff of 10% on the remaining 300 Billion Dollars of goods and products coming from China into our Country. This does not include the 250 Billion Dollars already Tariffed at 25%...\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "...We look forward to continuing our positive dialogue with China on a comprehensive Trade Deal and feel that the future between our two countries will be a very bright one!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 6\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "Things are going along very well with China. They are paying us Tens of Billions of Dollars made possible by their monetary devaluations and pumping in massive amounts of cash to keep their system going. So far our consumer is paying nothing - and no inflation. No help from Fed!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "China dropped the price of their currency to an almost a historic low. Itâ€™s called â€œcurrency manipulation.â€ Are you listening Federal Reserve? This is a major violation which will greatly weaken China over time!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "Based on the historic currency manipulation by China it is now even more obvious to everyone that Americans are not paying for the Tariffs â€“ they are being paid for compliments of China and the U.S. is taking in tens of Billions of Dollars! China has always....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "China is intent on continuing to receive the hundreds of Billions of Dollars they have been taking from the U.S. with unfair trade practices and currency manipulation. So one-sided it should have been stopped many years ago!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "@sundarpichai of Google was in the Oval Office working very hard to explain how much he liked me what a great job the Administration is doing that Google was not involved with Chinaâ€™s military that they didnâ€™t help Crooked Hillary over me in the 2016 Election and that they...\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Massive amounts of money from China and other parts of the world is pouring into the United States for reasons of safety investment and interest rates! We are in a very strong position. Companies are also coming to the U.S. in big numbers. A beautiful thing to watch!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -5\n",
      "-------------------------------------------\n",
      "As they have learned in the last two years our great American Farmers know that China will not be able to hurt them in that their President has stood with them and done what no other president would do - And Iâ€™ll do it again next year if necessary!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      "â€œThree more Central Banks cut rates.â€ Our problem is not China - We are stronger than ever money is pouring into the U.S. while China is losing companies by the thousands to other countries and their currency is under siege - Our problem is a Federal Reserve that is too.....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "Watching Sleepy Joe Biden making a speech. Sooo Boring! The LameStream Media will die in the ratings and clicks with this guy. It will be over for them not to mention the fact that our Country will do poorly with him. It will be one big crash but at least China will be happy!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "China wants to make a deal so badly. Thousands of companies are leaving because of the Tariffs they must stem the flow. At the same time China may be hoping for a Democrat to win so they could continue the great ripoff of America &amp; the theft of hundreds of Billions of $â€™s!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Through massive devaluation of their currency and pumping vast sums of money into their system the tens of billions of dollars that the U.S. is receiving is a gift from China. Prices not up no inflation. Farmers getting more than China would be spending. Fake News wonâ€™t report!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "As usual China said they were going to be buying â€œbigâ€ from our great American Farmers. So far they have not done what they said. Maybe this will be different!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "We are winning big time against China. Companies &amp; jobs are fleeing. Prices to us have not gone up and in some cases have come down. China is not our problem though Hong Kong is not helping. Our problem is with the Fed. Raised too much &amp; too fast. Now too slow to cut....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "Good things were stated on the call with China the other day. They are eating the Tariffs with the devaluation of their currency and â€œpouringâ€ money into their system. The American consumer is fine with or without the September date but much good will come from the short.....\n",
      "sentiment gauge guess:  7\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "..deferral to December. It actually helps China more than us but will be reciprocated. Millions of jobs are being lost in China to other non-Tariffed countries. Thousands of companies are leaving. Of course China wants to make a deal. Let them work humanely with Hong Kong first!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "I know President Xi of China very well. He is a great leader who very much has the respect of his people. He is also a good man in a â€œtough business.â€ I have ZERO doubt that if President Xi wants to quickly and humanely solve the Hong Kong problem he can do it. Personal meeting?\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "RT @realDonaldTrump: ..deferral to December. It actually helps China more than us but will be reciprocated. Millions of jobs are being losâ€¦\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "The Fake News Media is doing everything they can to crash the economy because they think that will be bad for me and my re-election. The problem they have is that the economy is way too strong and we will soon be winning big on Trade and everyone knows that including China!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -5\n",
      "-------------------------------------------\n",
      "Biden doesnâ€™t have a clue! I will solve the China problem. https://t.co/v0sAoVEAoB\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "â€œIf they donâ€™t get this Trade Deal with the U.S. done China could have it first recession (or worse!) in years. Thereâ€™s disinvestment in China right now. Also the Fed is too tight (I agree).â€ Steve Moore Heritage Foundation\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "We are doing very well with China and talking!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "Our economy is the best in the world by far. Lowest unemployment ever within almost all categories. Poised for big growth after trade deals are completed. Import prices down China eating Tariffs. Helping targeted Farmers from big Tariff money coming in. Great future for USA!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -6\n",
      "-------------------------------------------\n",
      "Doing great with China and other Trade Deals. The only problem we have is Jay Powell and the Fed. Heâ€™s like a golfer who canâ€™t putt has no touch. Big U.S. growth if he does the right thing BIG CUT - but donâ€™t count on him! So far he has called it wrong and only let us down....\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "Our Country has lost stupidly Trillions of Dollars with China over many years. They have stolen our Intellectual Property at a rate of Hundreds of Billions of Dollars a year &amp; they want to continue. I wonâ€™t let that happen! We donâ€™t need China and frankly would be far....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "....better off without them. The vast amounts of money made and stolen by China from the United States year after year for decades will and must STOP. Our great American companies are hereby ordered to immediately start looking for an alternative to China including bringing..\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  4\n",
      "-------------------------------------------\n",
      "....your companies HOME and making your products in the USA. I will be responding to Chinaâ€™s Tariffs this afternoon. This is a GREAT opportunity for the United States. Also I am ordering all carriers including Fed Ex Amazon UPS and the Post Office to SEARCH FOR &amp; REFUSE....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "....all deliveries of Fentanyl from China (or anywhere else!). Fentanyl kills 100000 Americans a year. President Xi said this would stop - it didnâ€™t. Our Economy because of our gains in the last 2 1/2 years is MUCH larger than that of China. We will keep it that way!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "For many years China (and many other countries) has been taking advantage of the United States on Trade Intellectual Property Theft and much more. Our Country has been losing HUNDREDS OF BILLIONS OF DOLLARS a year to China with no end in sight....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "....Sadly past Administrations have allowed China to get so far ahead of Fair and Balanced Trade that it has become a great burden to the American Taxpayer. As President I can no longer allow this to happen! In the spirit of achieving Fair Trade we must Balance this very....\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "...unfair Trading Relationship. China should not have put new Tariffs on 75 BILLION DOLLARS of United States product (politically motivated!). Starting on October 1st the 250 BILLION DOLLARS of goods and products from China currently being taxed at 25% will be taxed at 30%...\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "...Additionally the remaining 300 BILLION DOLLARS of goods and products from China that was being taxed from September 1st at 10% will now be taxed at 15%. Thank you for your attention to this matter!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "RT @TreasurySpox: U.S. Treasury Designates China as a Currency Manipulator: https://t.co/7OnySGjzH1\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "For all of the Fake News Reporters that donâ€™t have a clue as to what the law is relative to Presidential powers China etc. try looking at the Emergency Economic Powers Act of 1977. Case closed!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "When I looked up to the sky and jokingly said â€œI am the chosen oneâ€ at a press conference two days ago referring to taking on Trade with China little did I realize that the media would claim that I had a â€œMessiah complex.â€ They knew I was kidding being sarcastic and just....\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "\"RT @WhiteHouse: \"\"We have excess corn in various parts of our country with our farmers because China did not do what they said they were goiâ€¦\"\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "In France we are all laughing at how knowingly inaccurate the U.S. reporting of events and conversations at the G-7 is. These Leaders and many others are getting a major case study of Fake News at itâ€™s finest! Theyâ€™ve got it all wrong from Iran to China Tariffs to Boris!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "So interesting to read and see all of the free and interesting advice I am getting on China from people who have tried to handle it before and failed miserably - In fact they got taken to the cleaners. We are doing very well with China. This has never happened to them before!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 6\n",
      "deviation from actual scale:  -3\n",
      "-------------------------------------------\n",
      "General Motors which was once the Giant of Detroit is now one of the smallest auto manufacturers there. They moved major plants to China BEFORE I CAME INTO OFFICE. This was done despite the saving help given them by the USA. Now they should start moving back to America again?\n",
      "sentiment gauge guess:  2\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      "Just watched Congresswoman Debbie Dingell and many other Democrats wanting to give up on our very successful Trade battle with China which has had its worst Economic year in memory (and getting worse). We are taking in $Billions. Will be big for Farmers and ALL!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "Peter Morici Economist: Tariffs will not impact American consumers that much because the Chinese currency has gone down which gives our importers a discount. Importers can find suppliers outside of China. Absolutely worth it we donâ€™t want to be servants to the Chinese! This...\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "....is about American Freedom. Redirect the supply chain. There is no reason to buy everything from China!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "We are doing very well in our negotiations with China. While I am sure they would love to be dealing with a new administration so they could continue their practice of â€œripoff USAâ€($600 B/year)16 months PLUS is a long time to be hemorrhaging jobs and companies on a long-shot....\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "....And then think what happens to China when I win. Deal would get MUCH TOUGHER! In the meantime Chinaâ€™s Supply Chain will crumble and businesses jobs and money will be gone!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "For all of the â€œgeniusesâ€ out there many who have been in other administrations and â€œtaken to the cleanersâ€ by China that want me to get together with the EU and others to go after China Trade practices remember the EU &amp; all treat us VERY unfairly on Trade also. Will change!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "â€œThe Chinese are very adept at not accepting anything. Youâ€™ve got to be very tough and thatâ€™s what Trump is doing. Itâ€™s in Chinaâ€™s interest to correct and I think weâ€™ll end up with a solution thatâ€™s dramatically better than we have today. Frankly I think the impact of what....\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "....Trump is doing to China is not lost on the rest of the world. Europe has had among the most protectionist policies forever. Theyâ€™re sitting there and saying gee are we next? Maybe you are! Weâ€™ve got to change the rules. The U.S. canâ€™t defend the world and pay for it........\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "â€œU.S. Winning Trade War With China In Dollars.â€ CNBC\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 6\n",
      "deviation from actual scale:  -3\n",
      "-------------------------------------------\n",
      "1. Which country has the largest carbon emission reduction?AMERICA!2. Who has dumped the most carbon into the air?   CHINA!3. 91% of the worldâ€™s population are exposed to air pollution above the World Health Organizationâ€™s suggested level.   NONE ARE IN THE U.S.A.!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "â€œChina is eating the Tariffs.â€ Billions pouring into USA. Targeted Patriot Farmers getting massive Dollars from the incoming Tariffs! Good Jobs Numbers No Inflation(Fed). China having worst year in decades. Talks happening good for all!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "China just enacted a major stimulus plan. With all the Tariffs THEY are paying to the USA Billions and Billions of Dollars they need it! In the meantime our Federal Reserve sits back and does NOTHING!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "â€œChina suspends Tariffs on some U.S. products. Being hit very hard supply chains breaking up as many companies move or look to move to other countries. Much more expensive to China than originally thought.â€ @CNBC  @JoeSquawk\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 6\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      "RT @MariaBartiromo: China is moving to develop a more level playing field: Sen. Perdue https://t.co/97UZWyhiJu  @MorningsMaria @FoxBusiness\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "At the request of the Vice Premier of China Liu He and due to the fact that the People's Republic of China will be celebrating their 70th Anniversary....\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "It is expected that China will be buying large amounts of our agricultural products!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -5\n",
      "-------------------------------------------\n",
      "Producer prices in China shrank most in 3 years due to Chinaâ€™s big devaluation of their currency coupled with monetary stimulus. Federal Reserve not watching? Will Fed ever get into the game? Dollar strongest EVER! Really bad for exports. No Inflation...Highest Interest Rates...\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "â€œThe real story involves Hunter Biden going around the world and collecting large payments from foreign governments and foreign oligarchs.â€ Peter Schweizer  Laura Ingraham Hunter made a fortune in Ukraine and in China. He knew nothing about Energy or anything else.\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "....taken out of Ukraine and China. Additionally I demand transparency from Democrats that went to Ukraine and attempted to force the new President to do things that they wanted under the form of political threat.\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "The President of Ukraine said that he was NOT pressured by me to do anything wrong. Canâ€™t have better testimony than that! As V.P. Biden had his son on the other hand take out millions of dollars by strong arming the Ukrainian President. Also looted millions from China. Bad!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "â€œChina Trade Turmoil: China Urging a CALM AND RATIONAL Solution.â€ @MariaBartiromo @FoxBusiness China is doing very poorly while the USA under your favorite Presidentâ€™s leadership continues to soar to new heights - and despite the Do Nothing Democrats we have just begun!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "....place in TRADE itâ€™s taking shape in Military Competition.â€ Johnathan Ward author and China expert. We are winning and we will win. They should not have broken the deal we had with them. Happy Birthday China!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 1\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "The Fake News Media wants to stay as far away as possible from the Ukraine and China deals made by the Bidens. A Corrupt Media is so bad for our Country! In actuality the Media may be even more Corrupt than the Bidens which is hard to do!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "Congratulations to President Xi and the Chinese people on the 70th Anniversary of the Peopleâ€™s Republic of China!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 6\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "RT @DeFede: This morning in the Florida Keys @marcorubio was asked about the President calling on China to investigate @JoeBiden - see hisâ€¦\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Somebody please wake up Mitt Romney and tell him that my conversation with the Ukrainian President was a congenial and very appropriate one and my statement on China pertained to corruption not politics. If Mitt worked this hard on Obama he could have won. Sadly he choked!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  4\n",
      "-------------------------------------------\n",
      "....and separately got 1.5 Billion Dollars from China despite no experience and for no apparent reason. There is NO WAY these can be legitimate transactions? As lawyers &amp; others have stated as President I have an OBLIGATION to look into possible or probable CORRUPTION!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "....And by the way I would LOVE running against 1% Joe Biden - I just donâ€™t think itâ€™s going to happen. Sleepy Joe wonâ€™t get to the starting gate &amp; based on all of the money he &amp; his family probably â€œextortedâ€ Joe should hang it up. I wouldnâ€™t want him dealing with China &amp; U!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 2\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      ".@60Minutes â€œforgotâ€ to report that we are helping the great farmers of the USA to the tune of 28 Billion Dollars for the last two years paid for out of Tariffs paid to the United States by China for targeting the farmer. They devalued their currency therefore paying the cost!\n",
      "sentiment gauge guess:  2\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "I was elected on getting out of these ridiculous endless wars where our great Military functions as a policing operation to the benefit of people who donâ€™t even like the USA. The two most unhappy countries at this move are Russia &amp; China because they love seeing us bogged.....\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "RT @ABCPolitics: President Trump criticizes Steve Kerr and Gregg Popovich â€” both vocal critics of Trump â€” when asked about China putting prâ€¦\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "Big day of negotiations with China. They want to make a deal but do I? I meet with the Vice Premier tomorrow at The White House.\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "Good things are happening at China Trade Talk Meeting. Warmer feelings than in recent past more like the Old Days. I will be meeting with the Vice Premier today. All would like to see something significant happen!\n",
      "sentiment gauge guess:  7\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "One of the great things about the China Deal is the fact that for various reasons we do not have to go through the very long and politically complex Congressional Approval Process. When the deal is fully negotiated I sign it myself on behalf of our Country. Fast and Clean!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "RT @MariaBartiromo: USMCA passage China deal should be â€˜a one-two punchâ€™: Rep. Tom Reed https://t.co/WcBsEjjir3 @MorningsMaria @FoxBusiness\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  1\n",
      "-------------------------------------------\n",
      "So funny to watch Steve Kerr grovel and pander when asked a simple question about China. He chocked and looks weak and pathetic. Donâ€™t want him at the White House!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "The deal I just made with China is by far the greatest and biggest deal ever made for our Great Patriot Farmers in the history of our Country. In fact there is a question as to whether or not this much product can be produced? Our farmers will figure it out. Thank you China!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -6\n",
      "-------------------------------------------\n",
      "My deal with China is that they will IMMEDIATELY start buying very large quantities of our Agricultural Product not wait until the deal is signed over the next 3 or 4 weeks. THEY HAVE ALREADY STARTED! Likewise financial services and other deal aspects start preparing....\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -5\n",
      "-------------------------------------------\n",
      "....I agreed not to increase Tariffs from 25% to 30% on October 15th. They will remain at 25%. The relationship with China is very good. We will finish out the large Phase One part of the deal then head directly into Phase Two. The Phase One Deal can be finalized &amp; signed soon!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -3\n",
      "-------------------------------------------\n",
      "CHINA HAS ALREADY BEGUN AGRICULTURAL PURCHASES FROM OUR GREAT PATRIOT FARMERS &amp; RANCHERS!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      "....and Assad to protect the land of our enemy? Anyone who wants to assist Syria in protecting the Kurds is good with me whether it is Russia China or Napoleon Bonaparte. I hope they all do great we are 7000 miles away!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "A big scandal at @ABC News. They got caught using really gruesome FAKE footage of the Turks bombing in Syria. A real disgrace. Tomorrow they will ask softball questions to Sleepy Joe Bidenâ€™s son Hunter like why did Ukraine &amp; China pay you millions when you knew nothing? Payoff?\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "China and the USA are working on selecting a new site for signing of Phase One of Trade Agreement about 60% of total deal after APEC in Chile was canceled do to unrelated circumstances. The new location will be announced soon. President Xi and President Trump will do signing!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -3\n",
      "-------------------------------------------\n",
      "....our manufacturers. We should have lower interest rates than Germany Japan and all others. We are now by far the biggest and strongest Country but the Fed puts us at a competitive disadvantage. China is not our problem the Federal Reserve is! We will win anyway.\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "....Ukrainian energy company and more millions taken from China and now reports of other companies and countries also giving him big money are certainly looking very corrupt (to put it mildly!) to me. Both Bidens should be forced to testify in this No Due Process Scam!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 3\n",
      "deviation from actual scale:  3\n",
      "-------------------------------------------\n",
      "Our great Farmers will recieve another major round of â€œcashâ€ compliments of China Tariffs prior to Thanksgiving. The smaller farms and farmers will be big beneficiaries. In the meantime and as you may have noticed China is starting to buy big again. Japan deal DONE. Enjoy!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -5\n",
      "-------------------------------------------\n",
      "Just finished a very good &amp; cordial meeting at the White House with Jay Powell of the Federal Reserve. Everything was discused including interest rates negative interest low inflation easing Dollar strength &amp; its effect on manufacturing trade with China E.U. &amp; others etc.\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -6\n",
      "-------------------------------------------\n",
      "U.S. Markets are up as much as 21% since the announcement of Tariffs on 3/1/2018 - and the U.S. is taking in massive amounts of money (and giving some to our farmers who have been targeted by China)!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -5\n",
      "-------------------------------------------\n",
      "Why is the World Bank loaning money to China? Can this be possible? China has plenty of money and if they donâ€™t they create it. STOP!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "....with the U.S. Presidential Election in November. North Korea under the leadership of Kim Jong Un has tremendous economic potential but it must denuclearize as promised. NATO China Russia Japan and the entire world is unified on this issue!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "....Biden on the board of the largest natural gas company in Ukraine getting paid $83000 a month 10 times as much as a board member of @exxonmobil.â€ Thank you Ted. He also  made a fortune from China and others but zero before his father became V.P. @MeetThePress\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  2\n",
      "-------------------------------------------\n",
      "Getting VERY close to a BIG DEAL with China. They want it and so do we!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 8\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      "The Wall Street Journal story on the China Deal is completely wrong especially their statement on Tariffs. Fake News. They should find a better leaker!\n",
      "sentiment gauge guess:  4\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  0\n",
      "-------------------------------------------\n",
      "We have agreed to a very large Phase One Deal with China. They have agreed to many structural changes and massive purchases of Agricultural Product Energy and Manufactured Goods plus much more. The 25% Tariffs will remain as is with 7 1/2% put on much of the remainder....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 9\n",
      "deviation from actual scale:  -6\n",
      "-------------------------------------------\n",
      "Chuck Schumer sat for years during the Obama Administration and watched as China ripped off the United States. He &amp; the Do Nothing Democrats did NOTHING as this $ carnage took place. Now without even seeing it he snipes at our GREAT new deal with China. Too bad Cryinâ€™ Chuck!\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 5\n",
      "deviation from actual scale:  -2\n",
      "-------------------------------------------\n",
      "....energy independence manufacturing resilience illegal immigration coming down the Wall going up China confronted the caliphate defeated NAFTA renegotiated our militsry rebuilt NATO paying more regulations costing less.......and much more. This is why theyâ€™re....\n",
      "sentiment gauge guess:  3\n",
      "actual sentiment manual label: 4\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      ".@FoxNews  â€œTrump wins major victories in China and USMCA trade deals defense spending and Space Force.â€ Thank you!\n",
      "sentiment gauge guess:  6\n",
      "actual sentiment manual label: 7\n",
      "deviation from actual scale:  -1\n",
      "-------------------------------------------\n",
      "avg deviation: -0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "# check if the predictions are far/close to real annotated sentiment labels\n",
    "from collections import defaultdict\n",
    "deviation_counts = defaultdict(int)\n",
    "\n",
    "total_deviation = 0\n",
    "for tweet in train_textlist[201:]:\n",
    "    print(tweet[0])\n",
    "    print(\"sentiment gauge guess: \",cl.classify(tweet[0]))\n",
    "    print(\"actual sentiment manual label:\", tweet[1])\n",
    "    deviation = int(cl.classify(tweet[0])) - int(tweet[1])\n",
    "    print(\"deviation from actual scale: \",deviation)\n",
    "    total_deviation += deviation\n",
    "    print(\"-------------------------------------------\")\n",
    "    #print(\"total_deviation\",total_deviation)\n",
    "    deviation_counts[deviation] += 1\n",
    "\n",
    "  \n",
    "print(\"avg deviation:\",total_deviation/len(train_textlist[201:]))\n",
    "    \n",
    "##need  an summary accuracy score here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg deviation: -0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "print(\"avg deviation:\",total_deviation/len(train_textlist[201:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {-1: 26,\n",
       "             0: 24,\n",
       "             4: 4,\n",
       "             1: 25,\n",
       "             2: 19,\n",
       "             -2: 7,\n",
       "             3: 7,\n",
       "             -5: 6,\n",
       "             -6: 4,\n",
       "             -3: 4})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviation_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "\n",
    "Average deviation at -0.047 is not bad, but in the middle of prediction process, some predictions deviated 3-6 unit on the 0-9 scale. It's harder to evaluate accuracy when sentiment is on a wide ordinal scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-6, 4),\n",
       " (-5, 6),\n",
       " (-3, 4),\n",
       " (-2, 7),\n",
       " (-1, 26),\n",
       " (0, 24),\n",
       " (1, 25),\n",
       " (2, 19),\n",
       " (3, 7),\n",
       " (4, 4)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviation_counts_sorted =sorted(deviation_counts.items())\n",
    "deviation_counts_sorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "deviation_df = pd.DataFrame(deviation_counts_sorted,columns=[\"deviation\",\"count\"])#.set_index(\"deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviation</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deviation  count\n",
       "0         -6      4\n",
       "1         -5      6\n",
       "2         -3      4\n",
       "3         -2      7\n",
       "4         -1     26\n",
       "5          0     24\n",
       "6          1     25\n",
       "7          2     19\n",
       "8          3      7\n",
       "9          4      4"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('notebook')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.renderers.enable(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const spec = {\"config\": {\"view\": {\"width\": 400, \"height\": 300}, \"mark\": {\"tooltip\": null}}, \"data\": {\"name\": \"data-4cecd13a3c09808fd111c7c5500e0288\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"deviation\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"count\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v3.4.0.json\", \"datasets\": {\"data-4cecd13a3c09808fd111c7c5500e0288\": [{\"deviation\": -6, \"count\": 4}, {\"deviation\": -5, \"count\": 6}, {\"deviation\": -3, \"count\": 4}, {\"deviation\": -2, \"count\": 7}, {\"deviation\": -1, \"count\": 26}, {\"deviation\": 0, \"count\": 24}, {\"deviation\": 1, \"count\": 25}, {\"deviation\": 2, \"count\": 19}, {\"deviation\": 3, \"count\": 7}, {\"deviation\": 4, \"count\": 4}]}};\n",
       "const opt = {};\n",
       "const type = \"vega-lite\";\n",
       "const id = \"11b95a8e-0896-4a14-b415-0c7fead037ec\";\n",
       "\n",
       "const output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  const target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  const style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x1c297f9dc50>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#11b95a8e-0896-4a14-b415-0c7fead037ec"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "jupyter-vega": "#11b95a8e-0896-4a14-b415-0c7fead037ec"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alt.Chart(deviation_df).mark_bar().encode(\n",
    "x= 'deviation',\n",
    "y= 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952380952380952"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pred_no = deviation_df['count'].sum() #126\n",
    "accurate_no = deviation_df.query('deviation ==-1 |  deviation == 1| deviation ==0')['count'].sum() #75\n",
    "#if we consider predictions with deviation between [-1, 1] is accurate, accuracy rate is then:\n",
    "accurate_no/total_pred_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8015873015873016"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we consider deviations between [-2,2] is still accurate, soft accuracy rate is then:\n",
    "accurate_no = deviation_df.query('deviation ==-2 | deviation ==-1 | deviation ==2| deviation == 1| deviation ==0')['count'].sum() #101\n",
    "accurate_no/total_pred_no"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
